{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manwanth/transductive-transfer-learning-model/blob/main/transductive_learning_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l_bRskl9wF-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#MAKE UNIT VECTORS SPAN ENTIRE SPHERE\n",
        "#Increase radius of sphere\n",
        "\n",
        "!pip install POT\n",
        "!pip install torch torchvision\n",
        "!pip install pandas\n",
        "!pip install xlrd\n",
        "\n",
        "import numpy as np\n",
        "import ot\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "\n",
        "testS = pd.read_excel(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSoIsRZM8lEOHa-EhdpRARQTXwWR2XkqzUxMYIawB1QvPkQqgEjjBrjbwYpPw_ranveQm9dQi4cVpyT/pub?output=xlsx\")\n",
        "outputS = testS['label'].astype(int)\n",
        "inputS = testS.drop('label', axis=1)\n",
        "testT = pd.read_excel(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTcnrNGQHGuv3aYHfvdPB3RisDSHSfhjbPpSDYSF_rDUJO9B1w7q9y4pL4pet7dNnbUHrIcG3D-9Ycu/pub?output=xlsx\")\n",
        "#https://docs.google.com/spreadsheets/d/e/2PACX-1vQvONJZ6WIqsiw0hOoT-WvI9yowJJYXtsm7D-AmkmSifsoChEsYpNO87iRZ2-5MrIAuHrxlINzOQsN1/pub?output=xlsx\n",
        "outputT = testT['label'].astype(int)\n",
        "inputT = testT.drop('label', axis=1)\n",
        "#Source domain is bolded Sans\n",
        "#Target domain is light italic Sans\n",
        "\n",
        "def nsphereMap(tensor, radius):\n",
        "    return radius * F.normalize(tensor, dim=1)\n",
        "\n",
        "xS = nsphereMap(F.normalize(torch.tensor(inputS.values), dim=1),1).float()\n",
        "yS = torch.tensor(outputS.values, dtype=torch.float32).long()\n",
        "xT = nsphereMap(F.normalize(torch.tensor(inputT.values), dim=1),1).float()\n",
        "yT = torch.tensor(outputT.values, dtype=torch.float32).long()\n",
        "\n",
        "#Precausion for iteration\n",
        "new_xS = xS.clone()\n",
        "\n",
        "#Set up for OT\n",
        "xSweight = torch.ones(xS.size(0)) / xS.size(0)\n",
        "xTweight = torch.ones(xT.size(0)) / xT.size(0)\n",
        "\n",
        "#Cost\n",
        "def geodesic_cost(Xs_u: torch.Tensor, Xt_u: torch.Tensor) -> np.ndarray:\n",
        "\n",
        "    cos_sim = Xs_u @ Xt_u.T\n",
        "    cos_sim = cos_sim.clamp(-1.0, 1.0)\n",
        "    C = torch.acos(cos_sim)\n",
        "    return C.cpu().numpy()\n",
        "\n",
        "C = geodesic_cost(xS, xT)\n",
        "\n",
        "#OT\n",
        "P = ot.emd(xSweight, xTweight, torch.from_numpy(C))\n",
        "\n",
        "\n",
        "#Make source pinpoint on only one target\n",
        "def row_argmax_projection(P: np.ndarray) -> np.ndarray:\n",
        "    P_proj = np.zeros_like(P)\n",
        "    row_max_indices = np.argmax(P, axis=1)\n",
        "\n",
        "    for i, j in enumerate(row_max_indices):\n",
        "        P_proj[i, j] = P[i, j]\n",
        "    P_proj[P_proj != 0] = 1\n",
        "\n",
        "    return P_proj\n",
        "\n",
        "new_xT = torch.tensor(row_argmax_projection(P)) @ xT\n",
        "\n",
        "#Transfer everything if possible to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "xS, yS = xS.to(device), yS.to(device)\n",
        "xT, yT = xT.to(device), yT.to(device)\n",
        "new_xS, new_xT = new_xS.to(device), new_xT.to(device)\n",
        "\n",
        "\n",
        "# Angle between rows of two tensors\n",
        "def angle_between_rows(new_xS, Target):\n",
        "    cos_theta = torch.sum(new_xS * Target, dim=1) / (torch.norm(new_xS, dim=1) * torch.norm(Target, dim=1))\n",
        "    cos_theta = torch.clamp(cos_theta, -1.0, 1.0)\n",
        "    return torch.acos(cos_theta)  # shape: (N,)\n",
        "\n",
        "# Project new_xS onto Target (row-wise)\n",
        "def project_rows(new_xS, Target):\n",
        "    dot = torch.sum(new_xS * Target, dim=1, keepdim=True)\n",
        "    proj = dot / torch.sum(Target * Target, dim=1, keepdim=True) * Target\n",
        "    return proj  # shape: (N, d)\n",
        "\n",
        "\n",
        "\n",
        "# Main transformation:\n",
        "# new_xS * cos(aθ) + (proj(Target from new_xS)/‖proj(Target from new_xS)‖) * sin(aθ)\n",
        "def gradual_map(new_xS, Target, a):\n",
        "    theta = angle_between_rows(new_xS, Target)  # (N,)\n",
        "    proj = project_rows(new_xS, Target)\n",
        "    proj_norm = F.normalize(proj, dim=1)  # normalized projection direction\n",
        "\n",
        "    updated = (\n",
        "        new_xS * torch.cos(a * theta).unsqueeze(1) +\n",
        "        proj_norm * torch.sin(a * theta).unsqueeze(1)\n",
        "    )\n",
        "    new_xS[:] = updated\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(256, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 10),\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "# 1️⃣ Set seeds for reproducibility\n",
        "seed = 99\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# 2️⃣ Optional: for full determinism\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "#Activate Neural Network\n",
        "model = NeuralNetwork().to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "\n",
        "#Iterate through new source domains as they wrap around n-sphere\n",
        "\n",
        "# Choose which parameter to track\n",
        "param_name_to_track = 'linear_relu_stack.0.weight'  # first layer weights\n",
        "\n",
        "#Change numbers to track specific parameter\n",
        "row, col = 0, 0\n",
        "\n",
        "# Initialize storage for this single parameter\n",
        "param_snapshots = []\n",
        "\n",
        "# Training session parameters\n",
        "epochs_per_session = 50\n",
        "batch_size = 20\n",
        "max_sessions = 1000  # adjust as needed\n",
        "p = 0  # gradual_map angle counter\n",
        "\n",
        "while p < max_sessions:\n",
        "    # Step 1: Update new_xS globally\n",
        "    gradual_map(new_xS, new_xT, 0.05*p)  # modifies new_xS in-place\n",
        "\n",
        "    # Step 2: Prepare DataLoader\n",
        "    train_dataset = TensorDataset(new_xS, yS)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Step 3: Train the model\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for epoch in range(epochs_per_session):\n",
        "        for batch_x, batch_y in train_loader:\n",
        "          batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(batch_x)\n",
        "          loss = loss_fn(outputs, batch_y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "        running_loss += loss.item() * batch_x.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    \"\"\"print(f\"Session {p+1}, Training Loss: {epoch_loss:.4f}\")\"\"\"\n",
        "\n",
        "    # Step 4: Log only the chosen parameter element\n",
        "    param_value = model.linear_relu_stack[0].weight[row, col].item()\n",
        "    param_snapshots.append(param_value)\n",
        "\n",
        "    # Step 5: Evaluate source accuracy\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      preds_source = model(xS).argmax(dim=1)\n",
        "      accuracy_source = (preds_source == yS).float().mean().item()\n",
        "\n",
        "      preds_target = model(xT).argmax(dim=1)\n",
        "      accuracy_target = (preds_target == yT).float().mean().item()\n",
        "    \"\"\"\n",
        "    print(f\"Accuracy source: {accuracy_source:.4f}, target: {accuracy_target:.4f}\")\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Step 7: Increment angle\n",
        "    p += 1\n",
        "\n",
        "plt.plot(param_snapshots)\n",
        "plt.xlabel(\"Training session\")\n",
        "plt.ylabel(f\"{param_name_to_track}[{row},{col}] value\")\n",
        "plt.title(\"Tracked parameter evolution over sessions\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Evaluate final trained model on the target domain\n",
        "\"\"\"\n",
        "model.eval()  # set to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "rounds = len(xT)\n",
        "for _ in range(rounds):\n",
        "    idx = random.randint(0, len(xT) - 1)\n",
        "    single_x = xT[idx].unsqueeze(0).float()\n",
        "    single_y = yT[idx]\n",
        "    with torch.no_grad():\n",
        "        logits = model(single_x)\n",
        "        pred = logits.argmax(dim=1).item()\n",
        "    if pred == single_y:\n",
        "        correct += 1\n",
        "\n",
        "print(f\"Final accuracy on target domain: {correct/rounds:.4f}\")\n",
        "\"\"\"\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPsql2UtWHWYf/JEo8x6mn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}